---
version: '3'
volumes:
  esdata: null
  mysqldata: null
  zkdata: null
  neo4jdata: null
  atlasdata: null
services:
  #<------------ ZOOKEEPER ------------>
  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"
  # zookeeper:
  #   environment:
  #     - ZOOKEEPER_CLIENT_PORT=2181
  #     - ZOOKEEPER_TICK_TIME=2000
  #   hostname: zookeeper
  #   image: confluentinc/cp-zookeeper:5.4.0
  #   ports:
  #     - 2181:2181
  #   volumes:
  #     - zkdata:/var/opt/zookeeper

  #<------------ KAFKA ------------>
  kafka:
    depends_on:
    - zookeeper
    environment:
    - KAFKA_BROKER_ID=1
    - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
    - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
    - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
    - KAFKA_HEAP_OPTS=-Xms256m -Xmx256m
    hostname: kafka
    image: confluentinc/cp-kafka:5.4.0
    ports:
    - 29092:29092
    - 9092:9092

  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:5.3.6
    hostname: kafka-schema-registry
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: "zookeeper:2181"

  #control-center:
  #  image: confluentinc/cp-enterprise-control-center:6.0.4
  #  hostname: control-center
  #  logging:
  #    driver: none
  #  depends_on:
  #    - zookeeper
  #    - kafka
  #    - kafka-schema-registry
  #  ports:
  #    - "9021:9021"
  #  environment:
  #    CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
  #    CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #    CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://kafka-schema-registry:8081"
  #    CONTROL_CENTER_REPLICATION_FACTOR: 1
  #    CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #    CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #    CONFLUENT_METRICS_TOPIC_REPLICATION: 1
  #    PORT: 9021

  ##<------------ PYFLINK ------------>
  #pyflink-jobmanager:
  #  image: pyflink/playgrounds:1.13.0-rc2
  #  #build: ./images
  #  volumes:
  #    - ./app:/opt/app
  #  hostname: "pyflink-jobmanager"
  #  expose:
  #    - "6123"
  #  ports:
  #    - "8088:8088"
  #    - "8081:8081"
  #  command: jobmanager
  #  environment:
  #    - JOB_MANAGER_RPC_ADDRESS=pyflink-jobmanager
  #    
  #pyflink-taskmanager:
  #  image: pyflink/playgrounds:1.13.0-rc2
  #  volumes:
  #    - ./app:/opt/app
  #  expose:
  #    - "6121"
  #    - "6122"
  #  depends_on:
  #    - pyflink-jobmanager
  #  command: taskmanager
  #  links:
  #    - pyflink-jobmanager:pyflink-jobmanager
  #  environment:
  #    - JOB_MANAGER_RPC_ADDRESS=pyflink-jobmanager

  ##<------------ SPARK BITAMI IMAGE ------------>
  # spark-master:
  #   build: images/pyspark
  #   hostname: "spark-master"
  #   expose: 
  #     - "7077"
  #   volumes:
  #     - ./src/pyspark:/opt/app/pyspark
  #     - ./keys:/opt/app/keys
  #     - ./schemas:/opt/app/schemas
  #     - ./src/custom_recognizers:/opt/app/custom_recognizers
  #   environment: 
  #     - SPARK_MODE=master

  # spark-slave:
  #   build: images/pyspark
  #   hostname: "spark-slave"
  #   expose: 
  #     - "7077"
  #   environment: 
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_PORT=7075
  #     - SPARK_WORKER_WEBUI_PORT=8082
  #   depends_on:
  #     - spark-master
  #   volumes:
  #     - ./src/pyspark:/opt/app/pyspark
  #     - ./keys:/opt/app/keys
  #     - ./schemas:/opt/app/schemas
  #     - ./src/custom_recognizers:/opt/app/custom_recognizers
  
  # #<------------ DATA PRODUCER ---------->
  # producer:
  #   build: images/producer
  #   tty: true
  #   depends_on: 
  #     - kafka
  #   volumes:
  #     - ./src/data_generators:/opt/app/data_generators
  #     - ./src/dummy_data:/opt/app/dummy_data
  #     - ./src/pyflink:/opt/app/pyflink #remove when flink is ready
  #     - ./src/custom_recognizers:/opt/app/custom_recognizers #remove when flink is ready
  #     - ./keys:/opt/app/keys #remove when flink is ready
  #     - ./schemas:/opt/app/schemas #remove when flink is ready
      
  #<------------ DATAHUB ---------->
  
  # mysql:
  #   hostname: mysql
  #   image: mysql:5.7
  #   env_file: env/mysql.env
  #   ports:
  #     - "3306:3306"
  #   volumes:
  #     - ./init.sql:/docker-entrypoint-initdb.d/init.sql
  #     - mysqldata:/var/lib/mysql
  #   command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
    
  # elasticsearch:
  #   hostname: elasticsearch
  #   image: elasticsearch:7.9.3
  #   env_file: env/elasticsearch.env
  #   ports:
  #   - "9200:9200"
  #   volumes:
  #   - esdata:/usr/share/elasticsearch/data
  #   healthcheck:
  #       test: ["CMD-SHELL", "curl -sS --fail 'http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=0s' || exit 1"]
  #       interval: 60s
  #       timeout: 30s
  #       retries: 10
         
  # elasticsearch-setup:
  #   depends_on:
  #   - elasticsearch
  #   environment:
  #   - ELASTICSEARCH_HOST=elasticsearch
  #   - ELASTICSEARCH_PORT=9200
  #   - ELASTICSEARCH_PROTOCOL=http
  #   hostname: elasticsearch-setup
  #   image: linkedin/datahub-elasticsearch-setup:v0.8.14
  
  # kafka-setup:
  #   depends_on:
  #   - kafka
  #   - kafka-schema-registry
  #   environment:
  #   - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
  #   - KAFKA_BOOTSTRAP_SERVER=kafka:29092
  #   hostname: kafka-setup
  #   image: linkedin/datahub-kafka-setup:v0.8.14
    
  # mysql-setup:
  #   image: acryldata/datahub-mysql-setup:head
  #   hostname: mysql-setup
  #   environment:
  #     - MYSQL_HOST=mysql
  #     - MYSQL_PORT=3306
  #     - MYSQL_USERNAME=datahub
  #     - MYSQL_PASSWORD=datahub
  #     - DATAHUB_DB_NAME=datahub
  #   depends_on:
  #     - mysql
      
  # neo4j:
  #   container_name: neo4j
  #   environment:
  #   - NEO4J_AUTH=neo4j/datahub
  #   - NEO4J_dbms_default__database=graph.db
  #   - NEO4J_dbms_allow__upgrade=true
  #   hostname: neo4j
  #   image: neo4j:4.0.6
  #   ports:
  #   - 7474:7474
  #   - 7687:7687
  #   volumes:
  #   - neo4jdata:/data

  # datahub-gms:
  #     image: linkedin/datahub-gms:v0.8.14
  #     hostname: datahub-gms
  #     ports:
  #       - "8080:8080"
  #     depends_on:
  #       - elasticsearch-setup
  #       - kafka-setup
  #       - mysql
  #     environment:
  #       - DATASET_ENABLE_SCSI=false
  #       - EBEAN_DATASOURCE_USERNAME=datahub
  #       - EBEAN_DATASOURCE_PASSWORD=datahub
  #       - EBEAN_DATASOURCE_HOST=mysql:3306
  #       - EBEAN_DATASOURCE_URL=jdbc:mysql://mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8
  #       - EBEAN_DATASOURCE_DRIVER=com.mysql.jdbc.Driver
  #       - KAFKA_BOOTSTRAP_SERVER=kafka:29092
  #       - KAFKA_SCHEMAREGISTRY_URL=http://kafka-schema-registry:8081
  #       - ELASTICSEARCH_HOST=elasticsearch
  #       - ELASTICSEARCH_PORT=9200
  #       - JAVA_OPTS=-Xms1g -Xmx1g
  #       - ENTITY_REGISTRY_CONFIG_PATH=/datahub/datahub-gms/resources/entity-registry.yml
  #       - MAE_CONSUMER_ENABLED=true
  #       - MCE_CONSUMER_ENABLED=true
  #       - NEO4J_HOST=http://neo4j:7474
  #       - NEO4J_URI=bolt://neo4j
  #       - NEO4J_USERNAME=neo4j
  #       - NEO4J_PASSWORD=datahub
  #       #- GRAPH_SERVICE_IMPL=elasticsearch
  #       - GRAPH_SERVICE_IMPL=neo4j

  # datahub-frontend-react:
  #   image: linkedin/datahub-frontend-react:v0.8.14
  #   hostname: datahub-frontend-react
  #   ports:
  #     - "8082:9002"
  #   depends_on:
  #     - datahub-gms
  #   environment:
  #     - DATAHUB_GMS_HOST=datahub-gms
  #     - DATAHUB_GMS_PORT=8080
  #     - DATAHUB_SECRET=YouKnowNothing
  #     - DATAHUB_APP_VERSION=1.0
  #     - DATAHUB_PLAY_MEM_BUFFER_SIZE=10MB
  #     - JAVA_OPTS=-Xms512m -Xmx512m -Dhttp.port=9002 -Dconfig.file=datahub-frontend/conf/application.conf -Djava.security.auth.login.config=datahub-frontend/conf/jaas.conf -Dlogback.configurationFile=datahub-frontend/conf/logback.xml -Dlogback.debug=false -Dpidfile.path=/dev/null
  #     - KAFKA_BOOTSTRAP_SERVER=kafka:29092
  #     - DATAHUB_TRACKING_TOPIC=DataHubUsageEvent_v1
  #     - ELASTIC_CLIENT_HOST=elasticsearch
  #     - ELASTIC_CLIENT_PORT=9200
      
  # <------------ ATLAS ---------------->
  
  atlas:
    image: sansarip/apache-atlas
    expose:
      - "21000"
    ports:
      - "21000:21000"
    volumes:
      - atlasdata:/opt/apache-atlas-2.0.0
    depends_on:
      - "zookeeper"
      - "kafka"
      - "kafka-schema-registry"